{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from einops import rearrange, einsum\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision.models as models\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal_model = models.resnet18\n",
    "# internal_weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "\n",
    "internal_model = models.resnet34\n",
    "internal_weights = models.ResNet34_Weights.IMAGENET1K_V1\n",
    "\n",
    "# internal_model = models.resnet50\n",
    "# internal_weights = models.ResNet50_Weights.IMAGENET1K_V1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "x_train = np.load('x_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "## View some images\n",
    "# plt.imshow(x_train[2,:,:,: ] )\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# # convert to torch\n",
    "# x_train = torch.from_numpy(x_train)\n",
    "# x_test = torch.from_numpy(x_test)\n",
    "\n",
    "# y_train = torch.from_numpy(y_train)\n",
    "# y_test = torch.from_numpy(y_test)\n",
    "\n",
    "# print('X_train shape:\\t' ,x_train.shape)\n",
    "# print('Y_train shape\\t' ,y_train.shape)\n",
    "\n",
    "# print('X_test shape\\t' ,x_test.shape)\n",
    "# print('Y_test shape\\t' ,y_test.shape)\n",
    "\n",
    "# train_cut = 300\n",
    "# x_train = x_train[:train_cut]\n",
    "# y_train = y_train[:train_cut]\n",
    "\n",
    "# test_cut = 100\n",
    "# x_test = x_test[:test_cut]\n",
    "# y_test = y_test[:test_cut]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_fn = internal_weights.transforms()\n",
    "convert_to_tensor = transforms.ToTensor()\n",
    "\n",
    "# print('Transforms:\\n', transform_fn)\n",
    "\n",
    "def process_image(image):\n",
    "    image = convert_to_tensor(image)\n",
    "    # image = rearrange(image, 'h w c -> c h w')\n",
    "    image = transform_fn(image)\n",
    "    return image\n",
    "\n",
    "# transform images\n",
    "x_train_transformed = list(map(process_image, x_train))\n",
    "x_test_transformed = list(map(process_image, x_test))\n",
    "\n",
    "# stack images\n",
    "x_train_tensor = torch.stack(x_train_transformed) #.to(device)\n",
    "x_test_tensor = torch.stack(x_test_transformed) #.to(device)\n",
    "\n",
    "# convert labels to tensor\n",
    "y_train_tensor = torch.tensor(y_train) #.to(device)\n",
    "y_test_tensor = torch.tensor(y_test) #.to(device)\n",
    "\n",
    "y_train_tensor = y_train_tensor - 1\n",
    "y_test_tensor = y_test_tensor - 1\n",
    "\n",
    "# split train data into train and validation\n",
    "x_train_tensor, x_val_tensor, y_train_tensor, y_val_tensor = train_test_split(x_train_tensor, y_train_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# TensorDataset\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "val_data = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "test_data = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample, label = next(iter(train_loader))\n",
    "# print('Sample shape:', sample.shape)\n",
    "# print('Label shape:', label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/miniconda3/envs/ai/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1704987277512/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BiLinearModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BiLinearModel, self).__init__()\n",
    "        \n",
    "        self.cnn1 = internal_model(weights=internal_weights)\n",
    "        self.cnn2 = internal_model(weights=internal_weights)\n",
    "        \n",
    "\n",
    "        self.cnn1 = nn.Sequential(*list(self.cnn1.children())[:-2])\n",
    "        self.cnn2 = nn.Sequential(*list(self.cnn2.children())[:-2])\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.feature_size = internal_model(weights=internal_weights).fc.in_features\n",
    "        # print('Feature size:', self.feature_size)\n",
    "\n",
    "        # Define bilinear pooling\n",
    "        self.fc = nn.Linear(self.feature_size**2, num_classes) \n",
    "        # self.fc = nn.Sequential(\n",
    "        #     nn.Linear(self.feature_size**2, self.feature_size),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(self.feature_size, num_classes)\n",
    "        # )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.cnn1(x)\n",
    "        x2 = self.cnn2(x)\n",
    "        \n",
    "        # bilinear pooling with einops\n",
    "        x1 = rearrange(x1, 'b k h w -> b k (h w)')\n",
    "        x2 = rearrange(x2, 'b k h w -> b k (h w)')\n",
    "\n",
    "        # dropouts\n",
    "        x1 = self.dropout1(x1)\n",
    "        x2 = self.dropout2(x2)\n",
    "\n",
    "        x = einsum(x1, x2, 'b i j, b k j -> b i k')\n",
    "        # print('X shape:', x.shape)\n",
    "        x = rearrange(x, 'b i j -> b (i j)')\n",
    "        # print('X shape:', x.shape)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = BiLinearModel(num_classes=20)\n",
    "model = model.to(device)\n",
    "\n",
    "in_tensor = torch.randn(1, 3, 224, 224).to(device)\n",
    "model(in_tensor).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 19/19 [00:35<00:00,  1.87s/it, accuracy=0.0938, loss=194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 .Validation accuracy: 0.109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 19/19 [00:37<00:00,  1.96s/it, accuracy=0.0625, loss=3.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 .Validation accuracy: 0.046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20:  95%|█████████▍| 18/19 [00:35<00:01,  1.96s/it, accuracy=0.188, loss=2.5]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m lr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Unfreeze the weights and train again\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mcnn1\u001b[38;5;241m.\u001b[39mparameters():\n",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# update progress bar\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39mimage\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# accuracy\u001b[39;00m\n\u001b[1;32m     23\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    train_accuracy_list = []\n",
    "    val_accuracy_list = []\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
    "            for sample in train_loader:\n",
    "                image, label = sample\n",
    "                image, label = image.to(device), label.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(image)\n",
    "                loss = criterion(outputs, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # update progress bar\n",
    "                running_loss += loss.item()*image.size(0)\n",
    "\n",
    "                # accuracy\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                corrects = torch.sum(preds == label.data)\n",
    "                accuracy = corrects.double() / image.size(0)\n",
    "                \n",
    "                pbar.set_postfix(loss=running_loss/len(train_loader.dataset), accuracy=accuracy.item())\n",
    "                pbar.update(1)\n",
    "        train_accuracy_list.append(accuracy.item())\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        corrects = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for sample in val_loader:\n",
    "                image, label = sample\n",
    "                image, label = image.to(device), label.to(device)\n",
    "                outputs = model(image)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                corrects += torch.sum(preds == label.data)\n",
    "                total += image.size(0)\n",
    "        val_accuracy = corrects.double() / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Validation accuracy: {val_accuracy}\")\n",
    "        val_accuracy_list.append(val_accuracy)\n",
    "        model.train()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    res = {\n",
    "        'model': model,\n",
    "        'train_accuracy': train_accuracy_list,\n",
    "        'val_accuracy': val_accuracy_list\n",
    "        }\n",
    "\n",
    "    return res\n",
    "\n",
    "# Freeze the weights of the pre-trained models\n",
    "for param in model.cnn1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.cnn2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=1e-5, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Train the model\n",
    "train_res_freeze = train_model(model, criterion, optimizer, scheduler, num_epochs=20)\n",
    "model = train_res_freeze['model']\n",
    "\n",
    "# Unfreeze the weights and train again\n",
    "for param in model.cnn1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.cnn2.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-6, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Train the model again\n",
    "train_res_unfreeze = train_model(model, criterion, optimizer, scheduler, num_epochs=30)\n",
    "model = train_res_unfreeze['model']\n",
    "\n",
    "# evaluate the model\n",
    "model.eval()\n",
    "corrects = 0\n",
    "total = 0\n",
    "with tqdm(total=len(test_loader), desc=f\"Evaluating\") as pbar:\n",
    "    with torch.no_grad():\n",
    "        for sample in test_loader:\n",
    "            image, label = sample\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            outputs = model(image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            corrects += torch.sum(preds == label.data)\n",
    "            total += image.size(0)\n",
    "            pbar.update(1)\n",
    "print(f\"Accuracy: {corrects.double()/total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training and validation accuracy\n",
    "plt.plot(train_res_freeze['train_accuracy'], label='Train accuracy (Frozen weights)')\n",
    "plt.plot(train_res_freeze['val_accuracy'], label='Validation accuracy (Frozen weights)')\n",
    "plt.legend()\n",
    "plt.savefig('train_val_acc.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(train_res_unfreeze['train_accuracy'], label='Train accuracy (Unfrozen weights)')\n",
    "plt.plot(train_res_unfreeze['val_accuracy'], label='Validation accuracy (Unfrozen weights)')\n",
    "plt.legend()\n",
    "plt.savefig('train_val_acc_unfreeze.png')\n",
    "plt.close()\n",
    "\n",
    "# combine frozen and unfrozen training accuracy\n",
    "train_accuracy = train_res_freeze['train_accuracy'] + train_res_unfreeze['train_accuracy']\n",
    "val_accuracy = train_res_freeze['val_accuracy'] + train_res_unfreeze['val_accuracy']\n",
    "\n",
    "plt.plot(train_accuracy, label='Train accuracy')\n",
    "plt.plot(val_accuracy, label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('train_val_acc_combined.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bilinear pooling with einops\n",
    "# x1 = rearrange(x1, 'b k h w -> b k (h w)')\n",
    "# x2 = rearrange(x2, 'b k h w -> b k (h w)')\n",
    "# x = einsum('b i j, b k j -> b i k', x1, x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from einops import rearrange, einsum\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision.models as models\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal_model = models.resnet18\n",
    "# internal_weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "\n",
    "internal_model = models.resnet34\n",
    "internal_weights = models.ResNet34_Weights.IMAGENET1K_V1\n",
    "\n",
    "# internal_model = models.resnet50\n",
    "# internal_weights = models.ResNet50_Weights.IMAGENET1K_V1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:\t (791, 250, 250, 3)\n",
      "Y_train shape\t (791,)\n",
      "X_test shape\t (784, 250, 250, 3)\n",
      "Y_test shape\t (784,)\n"
     ]
    }
   ],
   "source": [
    "# Load images\n",
    "x_train = np.load('x_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "## View some images\n",
    "# plt.imshow(x_train[2,:,:,: ] )\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# # convert to torch\n",
    "# x_train = torch.from_numpy(x_train)\n",
    "# x_test = torch.from_numpy(x_test)\n",
    "\n",
    "# y_train = torch.from_numpy(y_train)\n",
    "# y_test = torch.from_numpy(y_test)\n",
    "\n",
    "print('X_train shape:\\t' ,x_train.shape)\n",
    "print('Y_train shape\\t' ,y_train.shape)\n",
    "\n",
    "print('X_test shape\\t' ,x_test.shape)\n",
    "print('Y_test shape\\t' ,y_test.shape)\n",
    "\n",
    "# train_cut = 300\n",
    "# x_train = x_train[:train_cut]\n",
    "# y_train = y_train[:train_cut]\n",
    "\n",
    "# test_cut = 100\n",
    "# x_test = x_test[:test_cut]\n",
    "# y_test = y_test[:test_cut]\n",
    "\n",
    "# print('X_train shape:\\t' ,x_train.shape)\n",
    "# print('X_train dtype:\\t' ,x_train.dtype)\n",
    "# print('X_train type:\\t' ,type(x_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforms:\n",
      " ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transform_fn = internal_weights.transforms()\n",
    "convert_to_tensor = transforms.ToTensor()\n",
    "\n",
    "print('Transforms:\\n', transform_fn)\n",
    "\n",
    "def process_image(image):\n",
    "    image = convert_to_tensor(image)\n",
    "    # image = rearrange(image, 'h w c -> c h w')\n",
    "    image = transform_fn(image)\n",
    "    return image\n",
    "\n",
    "# transform images\n",
    "x_train_transformed = list(map(process_image, x_train))\n",
    "x_test_transformed = list(map(process_image, x_test))\n",
    "\n",
    "# stack images\n",
    "x_train_tensor = torch.stack(x_train_transformed) #.to(device)\n",
    "x_test_tensor = torch.stack(x_test_transformed) #.to(device)\n",
    "\n",
    "# convert labels to tensor\n",
    "y_train_tensor = torch.tensor(y_train) #.to(device)\n",
    "y_test_tensor = torch.tensor(y_test) #.to(device)\n",
    "\n",
    "y_train_tensor = y_train_tensor - 1\n",
    "y_test_tensor = y_test_tensor - 1\n",
    "\n",
    "# add dimension to labels\n",
    "# y_train_tensor = y_train_tensor.unsqueeze(1)\n",
    "# y_test_tensor = y_test_tensor.unsqueeze(1)\n",
    "\n",
    "# TensorDataset\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape: torch.Size([32, 3, 224, 224])\n",
      "Label shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "sample, label = next(iter(train_loader))\n",
    "print('Sample shape:', sample.shape)\n",
    "print('Label shape:', label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BiLinearModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BiLinearModel, self).__init__()\n",
    "        \n",
    "        self.cnn1 = internal_model(weights=internal_weights)\n",
    "        self.cnn2 = internal_model(weights=internal_weights)\n",
    "        \n",
    "\n",
    "        self.cnn1 = nn.Sequential(*list(self.cnn1.children())[:-2])\n",
    "        self.cnn2 = nn.Sequential(*list(self.cnn2.children())[:-2])\n",
    "\n",
    "        self.feature_size = internal_model(weights=internal_weights).fc.in_features\n",
    "        # print('Feature size:', self.feature_size)\n",
    "\n",
    "        # Define bilinear pooling\n",
    "        self.fc = nn.Linear(self.feature_size**2, num_classes) \n",
    "        # nn.Sequential(\n",
    "        #     nn.Linear(512*512, 512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(512, num_classes)\n",
    "        # )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.cnn1(x)\n",
    "        x2 = self.cnn2(x)\n",
    "        \n",
    "        # bilinear pooling with einops\n",
    "        x1 = rearrange(x1, 'b k h w -> b k (h w)')\n",
    "        x2 = rearrange(x2, 'b k h w -> b k (h w)')\n",
    "        x = einsum(x1, x2, 'b i j, b k j -> b i k')\n",
    "        # print('X shape:', x.shape)\n",
    "        x = rearrange(x, 'b i j -> b (i j)')\n",
    "        # print('X shape:', x.shape)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = BiLinearModel(num_classes=20)\n",
    "# model = model.to(device)\n",
    "\n",
    "in_tensor = torch.randn(1, 3, 224, 224)#.to(device)\n",
    "model(in_tensor).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   4%|▍         | 1/24 [00:04<01:34,  4.10s/it, accuracy=0.0312, loss=3.84]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(10)\n",
      "Label: tensor(9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   8%|▊         | 2/24 [00:08<01:35,  4.34s/it, accuracy=0.156, loss=188]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(4)\n",
      "Label: tensor(18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  12%|█▎        | 3/24 [00:12<01:27,  4.18s/it, accuracy=0.0625, loss=786]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(6)\n",
      "Label: tensor(6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  17%|█▋        | 4/24 [00:16<01:22,  4.12s/it, accuracy=0.0312, loss=1.9e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(13)\n",
      "Label: tensor(18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  21%|██        | 5/24 [00:20<01:18,  4.11s/it, accuracy=0.125, loss=3.48e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(16)\n",
      "Label: tensor(15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  25%|██▌       | 6/24 [00:25<01:15,  4.19s/it, accuracy=0.125, loss=4.92e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(19)\n",
      "Label: tensor(12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  29%|██▉       | 7/24 [00:29<01:10,  4.17s/it, accuracy=0.125, loss=6.86e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(9)\n",
      "Label: tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  33%|███▎      | 8/24 [00:33<01:08,  4.30s/it, accuracy=0.344, loss=8.31e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(18)\n",
      "Label: tensor(18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  38%|███▊      | 9/24 [00:37<01:03,  4.26s/it, accuracy=0.219, loss=1.01e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(14)\n",
      "Label: tensor(11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  42%|████▏     | 10/24 [00:42<00:58,  4.20s/it, accuracy=0.0938, loss=1.29e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(5)\n",
      "Label: tensor(16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  46%|████▌     | 11/24 [00:46<00:53,  4.14s/it, accuracy=0.0938, loss=1.65e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(8)\n",
      "Label: tensor(10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  50%|█████     | 12/24 [00:50<00:49,  4.11s/it, accuracy=0.188, loss=1.92e+4] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(12)\n",
      "Label: tensor(6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  54%|█████▍    | 13/24 [00:54<00:45,  4.10s/it, accuracy=0.219, loss=2.12e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(2)\n",
      "Label: tensor(6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  58%|█████▊    | 14/24 [00:58<00:40,  4.06s/it, accuracy=0.219, loss=2.47e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(11)\n",
      "Label: tensor(8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  62%|██████▎   | 15/24 [01:02<00:36,  4.05s/it, accuracy=0.188, loss=2.7e+4] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(15)\n",
      "Label: tensor(15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  67%|██████▋   | 16/24 [01:06<00:32,  4.10s/it, accuracy=0.219, loss=2.89e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(15)\n",
      "Label: tensor(7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  71%|███████   | 17/24 [01:10<00:28,  4.11s/it, accuracy=0.438, loss=3.04e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(0)\n",
      "Label: tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  75%|███████▌  | 18/24 [01:14<00:24,  4.10s/it, accuracy=0.0625, loss=3.26e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(16)\n",
      "Label: tensor(17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  79%|███████▉  | 19/24 [01:18<00:20,  4.12s/it, accuracy=0.312, loss=3.39e+4] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(1)\n",
      "Label: tensor(17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  83%|████████▎ | 20/24 [01:22<00:16,  4.13s/it, accuracy=0.281, loss=3.57e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(3)\n",
      "Label: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  88%|████████▊ | 21/24 [01:26<00:12,  4.10s/it, accuracy=0.188, loss=3.76e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(9)\n",
      "Label: tensor(6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  92%|█████████▏| 22/24 [01:31<00:08,  4.14s/it, accuracy=0.312, loss=3.88e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(8)\n",
      "Label: tensor(18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  96%|█████████▌| 23/24 [01:35<00:04,  4.16s/it, accuracy=0.438, loss=3.98e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(17)\n",
      "Label: tensor(17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 24/24 [01:39<00:00,  4.14s/it, accuracy=0.188, loss=4.13e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(17)\n",
      "Label: tensor(15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:   4%|▍         | 1/24 [00:03<01:31,  3.96s/it, accuracy=0.406, loss=730]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(12)\n",
      "Label: tensor(12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:   8%|▊         | 2/24 [00:07<01:27,  3.99s/it, accuracy=0.531, loss=1.17e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(8)\n",
      "Label: tensor(8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  12%|█▎        | 3/24 [00:12<01:24,  4.03s/it, accuracy=0.438, loss=1.46e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(1)\n",
      "Label: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  17%|█▋        | 4/24 [00:16<01:20,  4.03s/it, accuracy=0.5, loss=1.91e+3]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(15)\n",
      "Label: tensor(16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  21%|██        | 5/24 [00:20<01:16,  4.05s/it, accuracy=0.531, loss=2.35e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(18)\n",
      "Label: tensor(18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  25%|██▌       | 6/24 [00:24<01:13,  4.07s/it, accuracy=0.5, loss=2.98e+3]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(9)\n",
      "Label: tensor(7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  29%|██▉       | 7/24 [00:28<01:08,  4.04s/it, accuracy=0.594, loss=3.31e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(3)\n",
      "Label: tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  33%|███▎      | 8/24 [00:32<01:04,  4.03s/it, accuracy=0.5, loss=3.84e+3]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(19)\n",
      "Label: tensor(19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  38%|███▊      | 9/24 [00:36<01:00,  4.04s/it, accuracy=0.562, loss=4.22e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(2)\n",
      "Label: tensor(13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  42%|████▏     | 10/24 [00:40<00:56,  4.02s/it, accuracy=0.688, loss=4.43e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(19)\n",
      "Label: tensor(11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  46%|████▌     | 11/24 [00:44<00:52,  4.07s/it, accuracy=0.656, loss=4.66e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(9)\n",
      "Label: tensor(9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  50%|█████     | 12/24 [00:49<00:52,  4.35s/it, accuracy=0.531, loss=5.08e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(19)\n",
      "Label: tensor(19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  54%|█████▍    | 13/24 [00:53<00:47,  4.31s/it, accuracy=0.406, loss=5.62e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(7)\n",
      "Label: tensor(6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  58%|█████▊    | 14/24 [00:57<00:42,  4.27s/it, accuracy=0.594, loss=6.04e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(7)\n",
      "Label: tensor(16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  62%|██████▎   | 15/24 [01:02<00:38,  4.25s/it, accuracy=0.688, loss=6.53e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(9)\n",
      "Label: tensor(9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  67%|██████▋   | 16/24 [01:06<00:33,  4.24s/it, accuracy=0.594, loss=6.89e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(12)\n",
      "Label: tensor(13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  71%|███████   | 17/24 [01:10<00:29,  4.24s/it, accuracy=0.594, loss=7.28e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(19)\n",
      "Label: tensor(19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  75%|███████▌  | 18/24 [01:14<00:25,  4.27s/it, accuracy=0.5, loss=7.59e+3]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor(16)\n",
      "Label: tensor(17)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
    "            for sample in train_loader:\n",
    "                image, label = sample\n",
    "                # image, label = image.to(device), label.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(image)\n",
    "                loss = criterion(outputs, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # update progress bar\n",
    "                running_loss += loss.item()*image.size(0)\n",
    "\n",
    "                # accuracy\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                corrects = torch.sum(preds == label.data)\n",
    "                accuracy = corrects.double() / image.size(0)\n",
    "                \n",
    "                pbar.set_postfix(loss=running_loss/len(train_loader.dataset), accuracy=accuracy.item())\n",
    "                pbar.update(1)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # validation\n",
    "        # model.eval()\n",
    "        # with torch.no_grad():\n",
    "        #     with tqdm(total=len(test_loader), desc=f\"Validation\") as pbar:\n",
    "        #         val_loss = 0.0\n",
    "        #         for sample in test_loader:\n",
    "        #             image, label = sample\n",
    "        #             image, label = image.to(device), label.to(device)\n",
    "        #             outputs = model(image)\n",
    "        #             loss = criterion(outputs, label)\n",
    "        #             val_loss += loss.item()*image.size(0)\n",
    "        #             # accuracy\n",
    "        #             _, preds = torch.max(outputs, 1)\n",
    "        #             corrects = torch.sum(preds == label.data)\n",
    "        #             accuracy = corrects.double() / image.size(0)\n",
    "        #             pbar.set_postfix(loss=val_loss/len(test_loader.dataset), accuracy=accuracy.item())\n",
    "        #             pbar.update(1)\n",
    "    return model\n",
    "\n",
    "# Freeze the weights of the pre-trained models\n",
    "for param in model.cnn1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.cnn2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=1e-4, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, criterion, optimizer, scheduler, num_epochs=10)\n",
    "\n",
    "# Unfreeze the weights and train again\n",
    "for param in model.cnn1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.cnn2.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-6, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Train the model again\n",
    "model = train_model(model, criterion, optimizer, scheduler, num_epochs=15)\n",
    "\n",
    "# evaluate the model\n",
    "model.eval()\n",
    "corrects = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for sample in test_loader:\n",
    "        image, label = sample\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        corrects += torch.sum(preds == label.data)\n",
    "        total += image.size(0)\n",
    "print(f\"Accuracy: {corrects.double()/total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bilinear pooling with einops\n",
    "# x1 = rearrange(x1, 'b k h w -> b k (h w)')\n",
    "# x2 = rearrange(x2, 'b k h w -> b k (h w)')\n",
    "# x = einsum('b i j, b k j -> b i k', x1, x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
